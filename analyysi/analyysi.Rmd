---
title: "Hiukassuodin- ja hiukassiloitinalgoritmit sekä niiden soveltaminen AoA-menetelmään perustuvassa Bluetooth-sisätilapaikannuksessa / Analyysi"
author: "Lasse Rintakumpu"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Ladataan tarvittavat kirjastot
library(truncnorm)
library(dplyr)
library(terra)
library(tidyr)
library(data.table)
library(raster)
library(readr)
library(sf)
library(sp)
library(matrixStats)
library(stats)
library(pracma)
# ja paikannusfunktio
source("R/pf_positioning.R")
source("R/total.R")
```

```{r}
# Ladataan testipolkudata
testipolku <- readr::read_csv("data/test_path.csv")
# Ilmaistaan testipolku tihennettynä pistejoukkona
testipolku_s <- as.data.frame(smoothr::smooth_densify(as.matrix(testipolku[,1:2]), n=1000))
colnames(testipolku_s) <- c("y", "x")

# Ladataan kartta-ggplot, polygonidatakehykset ja itse testidata
kartta <- readr::read_rds("data/sitemap_bw.RDS") 
polygonit_F <- readr::read_csv("data/inclusion_polygons.csv")
polygonit_E <- readr::read_csv("data/exclusion_polygons.csv")
y <- read_csv("data/y.csv")
```

```{r}
# Asetetaan käytetyt muuttujat
r <- 30 # Kuinka monta kertaa kukin parametrikombinaatio ajetaan
siemenluku <- 2666 # Asetetaan jokaisessa parametrikombinaatiossa käytetty siemenluku
persentiili <- 95 # Luottamusväleissä käytettävä persentiili
```

## Vaihe 1

Ensimmäisessä vaiheessa tarkastelaan partikkelien määrän $N={100,1000,10000}$ sekä uudelleenotannan kynnysarvon $resampling={0,1/10,2/3,1}$ vaikutusta paikannuskeskivirheeseen. Karttasovitusalgoritmia ei käytetä, kuten ei myöskään prediktiivistä siloitinta eikä signaalin vahvuuden kynnysarvoa. Dynaamisen mallin kohina-arvo $q=2.5$ pidettiin vakiona. Ensimmäisessä vaiheessa tarkasteltiin siis $12$ eri suunnitteluparametrikombinaatiota.

```{r}
N_values <- c(100,1000,10000)
resampling_values <- c(0,1/10,2/3,1)
phase1_values <- expand.grid(N=N_values, resampling=resampling_values)

phase1_results <- as.data.frame(matrix(ncol=8, nrow=nrow(phase1_values)))
phase1_results_list <- list()
colnames(phase1_results) <- c("q50_error", "q80_error", "q90_error", "q95_error", "sub_meter_quantile", "variance", "mc_variance", "run_time")

for(i in 1:nrow(phase1_values)) {
  set.seed(siemenluku)
  print(paste("Ajetaan parametrikombinaatio ", i, "/", nrow(phase1_values), sep=""))
  phase1_runs <- list()
  phase1_particles <- list()
  phase1_runtimes <- c()
  for(j in 1:r) {
   print(paste("Algoritmin ajokerta ", j, "/", r, sep=""))
   start_time <- Sys.time()
   phase1_runs[[j]] <- pf_positioning(y, N = phase1_values$N[i],
                                resampling = phase1_values$resampling[i],
                                exclusion_polygons = polygonit_E,
                                inclusion_polygons = polygonit_F,
                                map_matching = F, q = 2,
                                smoothing = F, rssi_threshold = -120,
                                P = 0, verbose=F, test_path = testipolku_s)[[1]]
   phase1_particles[[j]] <- pf_positioning(y, N = phase1_values$N[i],
                                resampling = phase1_values$resampling[i],
                                exclusion_polygons = polygonit_E,
                                inclusion_polygons = polygonit_F,
                                map_matching = F, q = 2,
                                smoothing = F, rssi_threshold = -120,
                                P = 0, verbose=F, test_path = testipolku_s)[[2]]
   end_time <- Sys.time()
   phase1_runtimes[j] <- as.numeric(difftime(end_time,start_time, units="secs"))
  }
  phase1_results_list[[i]] <- phase1_runs
  
  # Lasketaan MC-varianssi
  mc_variance <- c()
  mc_variance_k <- as.data.frame(matrix(ncol=r, nrow=n_distinct(phase1_particles[[1]]$k)))
  for(l in 1:length(phase1_particles)) {
    for(k in 1:n_distinct(phase1_particles[[1]]$k)) {
      mc_lon <- var(phase1_particles[[l]][eval(.(k))]$lon)
      mc_lat <- var(phase1_particles[[l]][eval(.(k))]$lat)
      mc_cov <- cov(phase1_particles[[l]][eval(.(k))]$lon, phase1_particles[[l]][eval(.(k))]$lat)
      Sigma <- matrix(data=c(mc_lon, mc_cov, 
                             mc_cov, mc_lat), ncol=2,nrow=2)
      mc_current <- sqrt(sum(Sigma*Sigma))
      mc_variance_k[k,l] <- mc_current
    }
    
    #mc_variance[k] <- (var(unlist(lapply(phase1_runs, function(x) x$x[k])),na.rm=T) + var(unlist(lapply(phase1_runs, function(x) x$y[k])),na.rm=T))/2
  }
  mc_variance <- apply(mc_variance_k, MARGIN=2, FUN=function(x) mean(x, na.rm=T))
  
  # Lasketaan ajojen ka.
  phase1_results[i,] <-  c(mean(unlist(lapply(phase1_runs, function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase1_runs, function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase1_runs, function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase1_runs, function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase1_runs, function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T),
                           mean(unlist(lapply(phase1_runs, function(x) median(x$variance, na.rm=T))),na.rm=T),
                           mean(mc_variance), mean(phase1_runtimes))
  
  
}
phase1_summary <- cbind(phase1_values, phase1_results)
phase1_summary$variance[1:3] <- NA

# Compute CI for each statistic and parameter combination
for(i in 1:length(phase1_results_list)) {
  phase1_results[i,"q50_error_lo"] <- phase1_results[i,"q50_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q50_error_hi"] <- phase1_results[i,"q50_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q80_error_lo"] <- phase1_results[i,"q80_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q80_error_hi"] <- phase1_results[i,"q80_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q90_error_lo"] <- phase1_results[i,"q90_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q90_error_hi"] <- phase1_results[i,"q90_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q95_error_lo"] <- phase1_results[i,"q95_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"q95_error_hi"] <- phase1_results[i,"q95_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"variance_lo"] <- phase1_results[i,"variance"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"variance_hi"] <- phase1_results[i,"variance"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase1_results[i,"sub_meter_quantile_lo"] <- phase1_results[i,"sub_meter_quantile"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
  phase1_results[i,"sub_meter_quantile_hi"] <- phase1_results[i,"sub_meter_quantile"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase1_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
}
phase1_summary <- cbind(phase1_values, phase1_results)
phase1_summary$variance[1:3] <- NA

#phase1_summary <- read_csv("data/tulokset_vaihe1_ci.csv")
#phase1_results_list <- read_rds("data/tulokset_vaihe1.RDS")
phase1_maps <- list()
for(i in 1:nrow(phase1_summary)) {
  phase1_maps[[i]] <- kartta
  for(j in 1:r) {
    # Lisätään ajojen polut karttaan
     phase1_maps[[i]] <- phase1_maps[[i]] + geom_path(data=phase1_results_list[[i]][[j]], aes(x=x,y=y), color="steelblue", alpha=0.8)
  }
  phase1_maps[[i]] <- phase1_maps[[i]] + ggtitle(paste("N=", phase1_summary[i, "N"],"; resampling=", round(phase1_summary[i, "resampling"],2), sep=""))
}

mc_variance <- c()
for(i in 1:nrow(phase1_values)) {
  # Lasketaan MC-varianssi jokaiselle parametrikombinaatiolle
  mc_variance_k <- c()
  phase1_runs <- phase1_results_list[[i]]
  for(k in 1:nrow(phase1_runs[[i]])) {
    
    # Mean of x
    mc_variance_mean_x <- mean(unlist(lapply(phase1_runs, function(x) x$x[k])), na.rm=T)
    mc_variance_mean_y <- mean(unlist(lapply(phase1_runs, function(x) x$y[k])), na.rm=T)
    mc_variance_x_k <- mean(unlist(lapply(phase1_runs, function(x) (x$x[k]-mc_variance_mean_x)^2)), na.rm=T)
    mc_variance_y_k <- mean(unlist(lapply(phase1_runs, function(x) (x$y[k]-mc_variance_mean_y)^2)), na.rm=T)
    mc_variance_cov_k <- mean(unlist(lapply(phase1_runs, function(x) (x$y[k]-mc_variance_mean_y)*(x$x[k]-mc_variance_mean_x))), na.rm=T)
    mc_variance_Sigma <- matrix(data=c(mc_variance_x_k, mc_variance_cov_k, 
                               mc_variance_cov_k, mc_variance_y_k), ncol=2,nrow=2)
    mc_variance_k[k] <- sqrt(sum(diag(mc_variance_Sigma*mc_variance_Sigma)))
  }
  # Parametrikombinaation MC-varianssi
  mc_variance[i] <- mean(mc_variance_k, na.rm=T)
}
phase1_summary$mc_variance <- mc_variance

write_csv(phase1_summary, "data/tulokset_vaihe1_ci.csv")
write_rds(phase1_results_list, "data/tulokset_vaihe1_ci.RDS")
write_rds(phase1_maps, "data/tulokset_vaihe1_kartat.RDS")
#do.call("grid.arrange", c(phase1_maps, ncol=3))


```


```{r}
# Plots
palette_values  <- c("black", "tomato", "steelblue", "purple") #c("#000000", "#E69F00", "#56B4E9", "#009E73")
p1 <- ggplot(phase1_summary, aes(x=N, y=q50_error, color=as.factor(round(resampling,2)), linetype=as.factor(round(resampling,2)))) + geom_point(data=phase1_summary, aes( 
       shape=as.factor(round(resampling,2)))) + geom_line() + ylab("Mediaanivirhe (m)") + scale_colour_manual(name = "resampling", values=palette_values) + scale_shape_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2))) + scale_linetype_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2))) #+  geom_ribbon(aes(ymin = q50_error_lo, ymax = q50_error_hi, fill=as.factor(round(resampling,2))), alpha=0.2, linetype=0) 

p2 <- ggplot(phase1_summary, aes(x=N, y=variance, color=as.factor(round(resampling,2)), linetype=as.factor(round(resampling,2)))) + geom_point(data=phase1_summary, aes( 
       shape=as.factor(round(resampling,2)))) + geom_line() + ylab("Varianssi") + scale_colour_manual(name = "resampling", values=palette_values) + scale_shape_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2))) + scale_linetype_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2)))

p3 <- ggplot(phase1_summary, aes(x=N, y=mc_variance, color=as.factor(round(resampling,2)), linetype=as.factor(round(resampling,2)))) + geom_point(data=phase1_summary, aes( 
       shape=as.factor(round(resampling,2)))) + geom_line() + ylab("MC-varianssi") + scale_colour_manual(name = "resampling", values=palette_values) + scale_shape_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2))) + scale_linetype_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2)))

p4 <- ggplot(phase1_summary, aes(x=N, y=run_time, color=as.factor(round(resampling,2)), linetype=as.factor(round(resampling,2)))) + geom_point(data=phase1_summary, aes( 
       shape=as.factor(round(resampling,2)))) + geom_line() + ylab("Ajoaika (s)") + scale_colour_manual(name = "resampling", values=palette_values) + scale_shape_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2))) + scale_linetype_manual(name = "resampling", values=as.factor(round(unique(phase1_summary$resampling),2)))

grid.arrange(p1,p2,p3,p4, ncol=1)
```

## Vaihe 2

Toisessa vaiheessa valitaan edellisen vaiheen tulosten perusteella parhaimman paikannusvirheen suhteessa suoritusaikaan ja varianssiin tuottava uudelleenotannan kynnysarvo $resampling$ sekä partikkelien määrä $N$. Nämä pidetään vakioarvoisina ja testataan karttasovitusalgoritmia *map_matching* $={T,F}$, karttasovitusalgoritmin rangaistusarvoa $P={1,100,1000}$ sekä dynaamisen mallin kohina-arvoa $q={0.75,1.5,2,2.5}$. Signaalin vahvuuden kynnysarvoa ei käytetä, kuten ei myöskään prediktiivistä siloitinta. Koska rangaistusarvo $P$ on käytössä ainoastaan karttasovitusalgoritmia käytettäessä, tarkastellaan toisessa vaiheessa $16$ eri suunnitteluparametrikombinaatiota.

```{r}
P <- c(0,100,1000)
q <- c(0.75,1.5,2,2.5)
phase2_values_a <- expand.grid(map_matching=T, P=P, q=q)
phase2_values_b <- expand.grid(map_matching=F, P=0, q=q)
phase2_values <- rbind(phase2_values_a, phase2_values_b)

phase2_results <- as.data.frame(matrix(ncol=8, nrow=nrow(phase2_values)))
phase2_results_list <- list()
colnames(phase2_results) <- c("q50_error", "q80_error", "q90_error", "q95_error", "sub_meter_quantile", "variance", "mc_variance", "run_time")

for(i in 1:nrow(phase2_values)) {
  set.seed(siemenluku)
  print(paste("Ajetaan parametrikombinaatio ", i, "/", nrow(phase2_values), sep=""))
  phase2_runs <- list()
  phase2_particles <- list()
  phase2_runtimes <- c()
  for(j in 1:r) {
   print(paste("Algoritmin ajokerta ", j, "/", r, sep=""))
   start_time <- Sys.time()
   phase2_runs[[j]] <- pf_positioning(y, N = 1000,
                                resampling = 2/3,
                                exclusion_polygons = polygonit_E,
                                inclusion_polygons = polygonit_F,
                                map_matching = phase2_values$map_matching[i], q = phase2_values$q[i],
                                smoothing = F, rssi_threshold = -120,
                                P = phase2_values$P[i], verbose=F, test_path = testipolku_s)[[1]]
   phase2_particles[[j]] <- pf_positioning(y, N = 1000,
                                resampling = 2/3,
                                exclusion_polygons = polygonit_E,
                                inclusion_polygons = polygonit_F,
                                map_matching = phase2_values$map_matching[i], q = phase2_values$q[i],
                                smoothing = F, rssi_threshold = -120,
                                P = phase2_values$P[i], verbose=F, test_path = testipolku_s)[[2]]
   end_time <- Sys.time()
   phase2_runtimes[j] <- as.numeric(difftime(end_time,start_time, units="secs"))
  }
  phase2_results_list[[i]] <- phase2_runs
  
  # Lasketaan MC-varianssi
  mc_variance <- c()
  mc_variance_k <- as.data.frame(matrix(ncol=r, nrow=n_distinct(phase2_particles[[1]]$k)))
  for(l in 1:length(phase2_particles)) {
    for(k in 1:n_distinct(phase2_particles[[1]]$k)) {
      mc_lon <- var(phase2_particles[[l]][eval(.(k))]$lon)
      mc_lat <- var(phase2_particles[[l]][eval(.(k))]$lat)
      mc_cov <- cov(phase2_particles[[l]][eval(.(k))]$lon, phase2_particles[[l]][eval(.(k))]$lat)
      Sigma <- matrix(data=c(mc_lon, mc_cov, 
                             mc_cov, mc_lat), ncol=2,nrow=2)
      mc_current <- sqrt(sum(Sigma*Sigma))
      mc_variance_k[k,l] <- mc_current
    }
    
    #mc_variance[k] <- (var(unlist(lapply(phase2_runs, function(x) x$x[k])),na.rm=T) + var(unlist(lapply(phase2_runs, function(x) x$y[k])),na.rm=T))/2
  }
  mc_variance <- apply(mc_variance_k, MARGIN=2, FUN=function(x) mean(x, na.rm=T))
  
  # Lasketaan ajojen ka.
  phase2_results[i,] <-  c(mean(unlist(lapply(phase2_runs, function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase2_runs, function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase2_runs, function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase2_runs, function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase2_runs, function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T),
                           mean(unlist(lapply(phase2_runs, function(x) median(x$variance, na.rm=T))),na.rm=T),
                           mean(mc_variance), mean(phase2_runtimes))
  
  
}

phase2_summary <- cbind(phase2_values, phase2_results)

# Compute CI for each statistic and parameter combination
for(i in 1:length(phase2_results_list)) {
  phase2_results[i,"q50_error_lo"] <- phase2_results[i,"q50_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q50_error_hi"] <- phase2_results[i,"q50_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q80_error_lo"] <- phase2_results[i,"q80_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q80_error_hi"] <- phase2_results[i,"q80_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q90_error_lo"] <- phase2_results[i,"q90_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q90_error_hi"] <- phase2_results[i,"q90_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q95_error_lo"] <- phase2_results[i,"q95_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"q95_error_hi"] <- phase2_results[i,"q95_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"variance_lo"] <- phase2_results[i,"variance"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"variance_hi"] <- phase2_results[i,"variance"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase2_results[i,"sub_meter_quantile_lo"] <- phase2_results[i,"sub_meter_quantile"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
  phase2_results[i,"sub_meter_quantile_hi"] <- phase2_results[i,"sub_meter_quantile"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase2_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
}
phase2_summary <- cbind(phase2_values, phase2_results)
#phase2_summary <- read_csv("data/tulokset_vaihe2_ci.csv")
#phase2_results_list <- read_rds("data/tulokset_vaihe2_ci.RDS")
phase2_maps <- list()
for(i in 1:nrow(phase2_summary)) {
  phase2_maps[[i]] <- kartta
  for(j in 1:r) {
    # Lisätään ajojen polut karttaan
     phase2_maps[[i]] <- phase2_maps[[i]] + geom_path(data=phase2_results_list[[i]][[j]], aes(x=x,y=y), color="steelblue", alpha=0.8)
  }
  phase2_maps[[i]] <- phase2_maps[[i]] + ggtitle(paste("map_matching=", 
                                                       phase2_summary[i, "map_matching"], "\nP=", 
                                                       phase2_summary[i, "P"],
                                                       "; q=", 
                                                       round(phase2_summary[i, "q"],2), sep=""))
}

#do.call("grid.arrange", c(phase2_maps, ncol=4))
#write_rds(phase2_maps, "data/tulokset_vaihe2_kartat.RDS")
#write_csv(phase2_summary, "data/tulokset_vaihe2_ci.csv")
#write_rds(phase2_results_list, "data/tulokset_vaihe2_ci.RDS")
```


```{r}
# Plots
p1 <- ggplot(phase2_summary, aes(x=q, y=q50_error, color=as.factor(round(P,2)), linetype=as.factor(round(P,2)))) + geom_point(data=phase2_summary, aes( 
       shape=as.factor(round(P,2)))) + geom_line() + ylab("Mediaanivirhe (m)") + scale_colour_manual(name = "P", values=palette_values) + scale_shape_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + scale_linetype_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + facet_wrap(vars(map_matching), labeller= "label_both")

p2 <- ggplot(phase2_summary, aes(x=q, y=variance, color=as.factor(round(P,2)), linetype=as.factor(round(P,2)))) + geom_point(data=phase2_summary, aes( 
       shape=as.factor(round(P,2)))) + geom_line() + ylab("Varianssi") + scale_colour_manual(name = "P", values=palette_values) + scale_shape_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + scale_linetype_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + facet_wrap(vars(map_matching), labeller= "label_both")

p3 <- ggplot(phase2_summary, aes(x=q, y=mc_variance, color=as.factor(round(P,2)), linetype=as.factor(round(P,2)))) + geom_point(data=phase2_summary, aes( 
       shape=as.factor(round(P,2)))) + geom_line() + ylab("MC-varianssi") + scale_colour_manual(name = "P", values=palette_values) + scale_shape_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + scale_linetype_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + facet_wrap(vars(map_matching), labeller= "label_both")

p4 <- ggplot(phase2_summary, aes(x=q, y=run_time, color=as.factor(round(P,2)), linetype=as.factor(round(P,2)))) + geom_point(data=phase2_summary, aes( 
       shape=as.factor(round(P,2)))) + geom_line() + ylab("Ajoaika") + scale_colour_manual(name = "P", values=palette_values) + scale_shape_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + scale_linetype_manual(name = "P", values=as.factor(round(unique(phase2_summary$P),2))) + facet_wrap(vars(map_matching), labeller= "label_both")
grid.arrange(p1,p2,p3,p4, ncol=1)
```

Viimeisessä vaiheessa valitaan edellisten vaihdeiden tulosten perusteella parhaimman paikannusvirheen suhteessa suoritusaikaan ja varianssiin tuottavat parametrit testattujen joukosta ($P=1000$, $q=1.5$, *map_matching=TRUE*) ja testataan datan valinnassa käytettävää signaalin vahvuuden kynnysarvoa *rssi_threshold* $={-120,-100,-90,-80}$ sekä prediktiivistä siloitinta *smoothing* $={T,F}$ eli kahdeksaa eri suunnitteluparametrikombinaatiota. Kynnysarvo $rssi_threshold$=$-120$ jättää kaikki havainnot dataan.

```{r}
rssi_threshold <- c(-120,-100,-90,-80)
smoothing <- c(T,F)
phase3_values <- expand.grid(rssi_threshold=rssi_threshold, smoothing=smoothing)
phase3_results <- as.data.frame(matrix(ncol=8, nrow=nrow(phase3_values)))
phase3_results_list <- list()
colnames(phase3_results) <- c("q50_error", "q80_error", "q90_error", "q95_error", "sub_meter_quantile", "variance", "mc_variance", "run_time")

for(i in 1:nrow(phase3_values)) {
  set.seed(siemenluku)
  print(paste("Ajetaan parametrikombinaatio ", i, "/", nrow(phase3_values), sep=""))
  phase3_runs <- list()
  phase3_runtimes <- c()
  for(j in 1:r) {
   print(paste("Algoritmin ajokerta ", j, "/", r, sep=""))
   start_time <- Sys.time()
   phase3_runs[[j]] <- pf_positioning(y, N = 1000,
                                resampling = 2/3,
                                exclusion_polygons = polygonit_E,
                                inclusion_polygons = polygonit_F,
                                map_matching = T, q = 0.75,
                                smoothing = phase3_values$smoothing[i], 
                                rssi_threshold = phase3_values$rssi_threshold[i],
                                P = 1000, verbose=F, test_path = testipolku_s)[[1]]
   end_time <- Sys.time()
   phase3_runtimes[j] <- as.numeric(difftime(end_time,start_time, units="secs"))
  }
  phase3_results_list[[i]] <- phase3_runs
  
  # Lasketaan MC-varianssi
  mc_variance <- c()
  for(k in 1:nrow(phase3_runs[[1]])) {
    mc_variance[k] <- (var(unlist(lapply(phase3_runs, function(x) x$x[k])),na.rm=T) + var(unlist(lapply(phase3_runs, function(x) x$y[k])),na.rm=T))/2
  }
  
  # Lasketaan ajojen ka.
  phase3_results[i,] <-  c(mean(unlist(lapply(phase3_runs, function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase3_runs, function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase3_runs, function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase3_runs, function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T),
                           mean(unlist(lapply(phase3_runs, function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T),
                           mean(unlist(lapply(phase3_runs, function(x) median(x$variance, na.rm=T))),na.rm=T),
                           mean(mc_variance), mean(phase3_runtimes))
  
  
}
phase3_summary <- cbind(phase3_values, phase3_results)
# Compute CI for each statistic and parameter combination
for(i in 1:length(phase3_results_list)) {
  phase3_results[i,"q50_error_lo"] <- phase3_results[i,"q50_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q50_error_hi"] <- phase3_results[i,"q50_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.5, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q80_error_lo"] <- phase3_results[i,"q80_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q80_error_hi"] <- phase3_results[i,"q80_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.8, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q90_error_lo"] <- phase3_results[i,"q90_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q90_error_hi"] <- phase3_results[i,"q90_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.9, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q95_error_lo"] <- phase3_results[i,"q95_error"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"q95_error_hi"] <- phase3_results[i,"q95_error"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) quantile(x$positioning_error, probs=0.95, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"variance_lo"] <- phase3_results[i,"variance"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"variance_hi"] <- phase3_results[i,"variance"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) median(x$variance, na.rm=T))),na.rm=T) / sqrt(r))
  phase3_results[i,"sub_meter_quantile_lo"] <- phase3_results[i,"sub_meter_quantile"] - (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
  phase3_results[i,"sub_meter_quantile_hi"] <- phase3_results[i,"sub_meter_quantile"] + (stats::qt(persentiili/100, df=(r-1)) * sd(unlist(lapply(phase3_results_list[[i]], function(x) ecdf(x$positioning_error[!is.na(x$positioning_error)])(1))),na.rm=T) / sqrt(r))
}
phase3_summary <- cbind(phase3_values, phase3_results)

#phase3_summary <- read_csv("data/tulokset_vaihe3_ci.csv")
#phase3_results_list <- read_rds("data/tulokset_vaihe3_ci.RDS")
phase3_maps <- list()
for(i in 1:nrow(phase3_summary)) {
  phase3_maps[[i]] <- kartta
  for(j in 1:r) {
    # Lisätään ajojen polut karttaan
     phase3_maps[[i]] <- phase3_maps[[i]] + geom_path(data=phase3_results_list[[i]][[j]], aes(x=x,y=y), color="steelblue", alpha=0.8)
  }
  phase3_maps[[i]] <- phase3_maps[[i]] + ggtitle(paste("smoothing=", 
                                                       phase3_summary[i, "smoothing"], "\nrssi_threshold=", 
                                                       phase3_summary[i, "rssi_threshold"], sep=""))
}

write_csv(phase3_summary, "data/tulokset_vaihe3_ci.csv")
write_rds(phase3_results_list, "data/tulokset_vaihe3_ci.RDS")
write_rds(phase3_maps, "data/tulokset_vaihe3_kartat.RDS")
#do.call("grid.arrange", c(phase3_maps, ncol=4))

```

```{r}
p1 <- ggplot(phase3_summary, aes(x=rssi_threshold, y=q50_error)) + geom_point() + geom_line() + ylab("Mediaanivirhe (m)") + facet_wrap(vars(smoothing), labeller= "label_both")
p2 <- ggplot(phase3_summary, aes(x=rssi_threshold, y=variance)) + geom_point() + geom_line() + ylab("Varianssi") + facet_wrap(vars(smoothing), labeller= "label_both")
p3 <- ggplot(phase3_summary, aes(x=rssi_threshold, y=mc_variance)) + geom_point() + geom_line() + ylab("MC-varianssi") + facet_wrap(vars(smoothing), labeller= "label_both")
p4 <- ggplot(phase3_summary, aes(x=rssi_threshold, y=run_time)) + geom_point() + geom_line() + ylab("Ajoaika") + facet_wrap(vars(smoothing), labeller= "label_both")
grid.arrange(p1,p2,p3,p4, ncol=1)
```

Luodaan myös triangulaatioestimaatit ToTaL-algoritmilla ja lasketaan näiden keskiarvo.

```{r}
t <- dplyr::n_distinct(floor(y$ts))
total_estimates <- as.data.frame(matrix(ncol=4, nrow=t))
colnames(total_estimates) <- c("x", "y", "D", "positioning_error")
i <- 1
for(ts_k in unique(floor(y$ts))) {
  y_subset <- y %>% dplyr::filter(floor(ts) == ts_k)
  total_results <- total(y_subset)
  if(length(total_results)==1) {
    total_estimates[i,1:3] <- c(NA,NA,NA)
  } else {
    total_estimates[i,1:3] <- total_results[1:3]
  }
  
  # Compute distance to the true path i.e. positioning error for this time step
  total_estimates[i,"positioning_error"] <- min(raster::pointDistance(t(matrix(c(total_estimates[i, "x"],
                                                              total_estimates[i, "y"]))), 
                                                   cbind(testipolku_s$x, testipolku_s$y), lonlat=F))
  
  i <- i + 1
}

total_ecdf <- ecdf(total_estimates$positioning_error[!is.na(total_estimates$positioning_error)])
total_statistics <- round(c(median(total_estimates$positioning_error, na.rm=T), 
                            mean(total_estimates$positioning_error, na.rm=T),
                            sd(total_estimates$positioning_error, na.rm=T),
                            total_ecdf(1)),2)

```

